# FADE: A Novel Approach for Fake Image Detection

In this repo, I will present and test a unique approach, which can be used to create state-of-art models designed for fake (generated) image detection. The method is called **Fake and Authentic Discrimination by Embeddings (FADE)**. It is based on fine-tuning transformers using contrastive learning. The code and detailed explanations are provided in the notebook ```FADE_A_Novel_Approach_for_Fake_Image_Detection.ipynb```.

The models and datasets associated with Project Checkpoints are located [here](https://drive.google.com/drive/folders/15htKJGVM-C02koeV4tnB93urthV4qCXv?usp=sharing).

As the quality of generated images improves exponentially, the need for models that correctly classify them as "real" or "generated" also rises. In this work, I would like to present a novel method for training such models. I am going to test it and decide whether the hypothesis that this method is better (in terms of accuracy and/or efficiency) is true. The goal of this project itself is not to create a state-of-art model but rather to perform a Proof of Concept (PoC). The experiments of the project will be conducted using the resources provided by the Free Version of Google Colab. These come with several limitations but it is expected for them to be enough to perform PoC.

As mentioned, the new approach is called Fake and Authentic Discrimination by Embeddings (FADE). In short, the structure behind the methodology of FADE is as follows:

The first step is to find and load a dataset consisting of real images only. Using a transformer, we create captions for these images, which are then used to generate fake images using another transformer. The next (arguably the most crucial) step is to slightly fine-tune an embedding model to create different embeddings for real and generated images, while also preserving their meaning. The fine-tuning will be based on contrastive learning. The final part of the method is to freeze the embedder and attach a head to it, which will be used for the classification.

Throughout the notebook, we will go into more detail for each step.

Similar approaches have been discovered and related research has been conducted. Nonetheless, FADE has not yet been tested. The model shows a strong performance vs. Stable Diffusion v1.5 with an accuracy of 96% on the test set. It beats all of the models mentioned by Nan Zhong et al. (2023).

FADE offers several benefits over other methods: achieves high accuracy and offers computational efficiency. The embedder and the classifier were trained on lower-resolution images ((224, 224)) and required a low amount of samples (1,000 per class, 2,000 in total). Another strength of FADE is that it requires minimal hyperparameter tuning. This is because the embedder is not fine-tuned until full convergence, and the classification task remains straightforward since the embedder has already learned to distinguish between the embeddings of real and fake images. As mentioned at the beginning of the notebook, the objective was not mainly to create a robust model but to test the approach (FADE). FADE can be applied using various generative models and embedders. Based on the results stated in the notebook, the method is expected to work excellently on a variety of datasets with images generated by a different model or combination of models.

## Table of Contents

1. Introduction and Objectives
2. Related Work
3. Data Loading and Preparation
4. Image Captioning
5. Image Generation from Captions
6. Contrastive Learning for Fine-Tuning
7. Real vs. Fake Image Classification
8. Summary and Findings
9. Future Directions and Improvements
